{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cp {a_file} ./local.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<HDF5 file \"local.nc\" (mode r)>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lhds = h5py.File('local.nc','r')\n",
    "lhds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flux' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-df312958fa69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHDF5AttrsEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'flux' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "class HDF5AttrsEncoder(json.JSONEncoder):\n",
    "    def __init__(self, file):\n",
    "        self.hd5file = file\n",
    "        \n",
    "    def default(self, obj):\n",
    "        if isinstance(obj,np.generic):\n",
    "            return obj.item()\n",
    "        if isinstance(obj, h5py.Reference):\n",
    "            return self.hd5file[obj].name\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            obj = obj.tolist()\n",
    "            return obj\n",
    "        if isinstance(obj, (np.bytes_, bytes)):\n",
    "            try:\n",
    "                return obj.decode('utf-8')\n",
    "            except UnicodeDecodeError:\n",
    "                print(f'couldn\\'t decode {obj}')\n",
    "                pass\n",
    "        \n",
    "        # Let the base class default method raise the TypeError\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "    \n",
    "json.dumps({k:v for k,v in flux.attrs.items()}, default=HDF5AttrsEncoder(flux.file).default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tiledb\n",
    "\n",
    "class DSBuilder():\n",
    "    def __init__(self, root, file):\n",
    "        self.groups = set()\n",
    "        self.root = root\n",
    "        self.file = file\n",
    "        \n",
    "        \n",
    "    def build(self):\n",
    "        self.handle_group('/', self.file)\n",
    "        self.file.visititems(self.visit)\n",
    "        \n",
    "        \n",
    "    def visit(self, member_name, obj):\n",
    "        # TODO Root attrs?\n",
    "        if isinstance(obj, h5py.Group):\n",
    "            self.handle_group(member_name, obj)\n",
    "        elif isinstance(obj, h5py.Dataset):\n",
    "            self.handle_ds(member_name, obj)\n",
    "        else:\n",
    "            raise RuntimeError(f\"What is this {obj}\")\n",
    "            \n",
    "    def handle_ds(self, ds_name, ds):\n",
    "        # TODO - what if ds visited before group?\n",
    "        ds_path = ds_name.rsplit('/',1)\n",
    "        if len(ds_path) == 1:\n",
    "            group = None\n",
    "            ds_base_name = ds_path[0]\n",
    "        elif ds_path[0].strip() == '':\n",
    "            group = None\n",
    "            ds_base_name = ds_path[1]\n",
    "        else:\n",
    "            group = ds_path[0]\n",
    "            ds_base_name = ds_path[1]\n",
    "            \n",
    "        print(f'make ds {ds_base_name} in group {group}')\n",
    "\n",
    "        if len(ds.shape) == 0:\n",
    "            self.create_scaler(group, ds_name, ds)\n",
    "        else:\n",
    "            self.create_array(group, ds_name, ds)\n",
    "        \n",
    "    def handel_var_attrs(self, ds_name, ds):\n",
    "        for k,v in  flux.attrs.items():\n",
    "            \n",
    "            print(f\"{k}:{v}\")\n",
    "        \n",
    "    def handle_group(self, group_name, group):\n",
    "        # TODO group attrs?\n",
    "        print(\"group name\", group_name)\n",
    "        path = os.path.join(self.root, group_name[1:] if group_name[0] == '/' else group_name )\n",
    "        os.makedirs(path, exist_ok=False)\n",
    "        tiledb.group_create(path)\n",
    "        print(f\"made_group {group_name} a {path}\")\n",
    "        with open(os.path.join(path,'attrs.json'),'w') as fp:\n",
    "            json.dump({k:v for k,v in group.attrs.items()}, fp, default=HDF5AttrsEncoder(self.file).default)\n",
    "        print(f'wrote group attrs for {group_name}')\n",
    "        \n",
    "    def __get_path(self, group, ds_name):\n",
    "        location = os.path.join(self.root, ds_name)\n",
    "        \n",
    "        if group and group is not \"/\":\n",
    "            location = os.path.join(self.root,group,ds_name)\n",
    "        return location\n",
    "        \n",
    "    def create_scaler(self, group, ds_name, ds):\n",
    "        # TODO: this is doggy!\n",
    "        location = self.__get_path(group, ds_name)\n",
    "        os.mkdir(location)\n",
    "        with open(os.path.join(location, \"value\"), 'w') as fp:\n",
    "            val = ds[()]\n",
    "            fp.write(str(val.item()))\n",
    "            \n",
    "        with open(os.path.join(location,'attrs.json'),'w') as fp:\n",
    "            json.dump({k:v for k,v in ds.attrs.items()}, fp,\n",
    "                      default=HDF5AttrsEncoder(self.file).default)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def create_array(self, group, ds_name, ds):\n",
    "        location = self.__get_path(group, ds_name)\n",
    "        os.mkdir(location)\n",
    "        \n",
    "        tile = 100\n",
    "        domain_indexs = [tiledb.Dim(name=f\"d{i}\", domain=(0,  np.iinfo(np.uint64).max-tile), tile=tile, dtype=np.uint64) for i in range(len(ds.shape))]\n",
    "        \n",
    "        data_type = {\n",
    "            \"float32\":np.float32,\n",
    "            \"float64\":np.float64,\n",
    "            \"int16\":np.int16,\n",
    "            \"int32\":np.int32,\n",
    "            \"int8\":np.int8,          \n",
    "        }[ds.dtype.name]\n",
    "\n",
    "            \n",
    "        # The array will be 4x4 with dimensions \"d1\" and \"d2\", with domain [1,4].\n",
    "        dom = tiledb.Domain(*domain_indexs)\n",
    "\n",
    "        # The array will be dense with a single attribute \"a\" so each (i,j) cell can store an integer.\n",
    "        schema = tiledb.ArraySchema(domain=dom, sparse=False,\n",
    "                                    attrs=[tiledb.Attr(name=ds_name, dtype=data_type)])\n",
    "\n",
    "        # Create the (empty) array on disk.\n",
    "        tiledb.DenseArray.create(location, schema)\n",
    "        \n",
    "        with tiledb.open(location,'w') as A:\n",
    "            \n",
    "            for k, v in ds.attrs.items():\n",
    "                encoded_v = json.dumps(v, default=HDF5AttrsEncoder(self.file).default)\n",
    "                A.meta[k] = encoded_v\n",
    "            \n",
    "            if 'DIMENSION_LIST' not in ds.attrs.keys():\n",
    "                if len(ds.shape) != 1:\n",
    "                    raise RuntimeError(f'No \"DIMENSION_LIST\" but shape!= 1 {ds_name}, {ds.shape}')\n",
    "                A.meta['DIMENSION_LIST'] = json.dumps([[ds_name]])\n",
    "            \n",
    "            data_domain = tuple([slice(0,i,None) for i in ds.shape])\n",
    "            data = ds[()]\n",
    "            \n",
    "            A[data_domain] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "group name /\nmade_group / a ./myds/\nwrote group attrs for /\nmake ds bnds in group None\nmake ds forecast_period in group None\nmake ds forecast_period_bnds in group None\nmake ds forecast_reference_time in group None\nmake ds grid_latitude in group None\nmake ds grid_longitude in group None\nmake ds precipitation_flux in group None\nmake ds rotated_latitude_longitude in group None\nmake ds time in group None\nmake ds time_bnds in group None\n"
    }
   ],
   "source": [
    "!rm -rf ./myds\n",
    "builder = DSBuilder('./myds',lhds )\n",
    "builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}