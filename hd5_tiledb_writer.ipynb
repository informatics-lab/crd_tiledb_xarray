{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/cssp-china/sample-data-17-01-20/cssp_china_pp_nc/precipitation_flux/precipitation_flux_apepda.pa546i0.nc'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLE_DATA_PATH=\"/data/cssp-china/sample-data-17-01-20/cssp_china_pp_nc/precipitation_flux\"\n",
    "files = !ls {SAMPLE_DATA_PATH} |head\n",
    "a_file = os.path.join(SAMPLE_DATA_PATH, files[4])\n",
    "a_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"precipitation_flux_apepda.pa546i0.nc\" (mode r)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hds = h5py.File(a_file,'r')\n",
    "hds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['bnds', 'forecast_period', 'forecast_period_bnds', 'forecast_reference_time', 'grid_latitude', 'grid_longitude', 'precipitation_flux', 'rotated_latitude_longitude', 'time', 'time_bnds']>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"precipitation_flux\": shape (10, 219, 286), type \"<f4\">"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flux = hds['precipitation_flux']\n",
    "flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DIMENSION_LIST',\n",
       "  array([array([<HDF5 object reference>], dtype=object),\n",
       "         array([<HDF5 object reference>], dtype=object),\n",
       "         array([<HDF5 object reference>], dtype=object)], dtype=object)),\n",
       " ('_Netcdf4Dimid', 0),\n",
       " ('standard_name', b'precipitation_flux'),\n",
       " ('units', b'kg m-2 s-1'),\n",
       " ('um_stash_source', b'm01s05i216'),\n",
       " ('cell_methods', b'time: mean (interval: 1 hour)'),\n",
       " ('grid_mapping', b'rotated_latitude_longitude'),\n",
       " ('coordinates', b'forecast_period forecast_reference_time')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k,v) for k,v in flux.attrs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 object reference>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = flux.attrs['DIMENSION_LIST'][0][0]\n",
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"time\": shape (10,), type \"<f8\">"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flux.file[ref]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"time\": shape (10,), type \"<f8\">"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hds[ref]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnds\n",
      "<HDF5 dataset \"bnds\": shape (2,), type \">f4\">\n",
      "forecast_period\n",
      "<HDF5 dataset \"forecast_period\": shape (10,), type \"<f8\">\n",
      "forecast_period_bnds\n",
      "<HDF5 dataset \"forecast_period_bnds\": shape (10, 2), type \"<f8\">\n",
      "forecast_reference_time\n",
      "<HDF5 dataset \"forecast_reference_time\": shape (), type \"<f8\">\n",
      "grid_latitude\n",
      "<HDF5 dataset \"grid_latitude\": shape (219,), type \"<f4\">\n",
      "grid_longitude\n",
      "<HDF5 dataset \"grid_longitude\": shape (286,), type \"<f4\">\n",
      "precipitation_flux\n",
      "<HDF5 dataset \"precipitation_flux\": shape (10, 219, 286), type \"<f4\">\n",
      "rotated_latitude_longitude\n",
      "<HDF5 dataset \"rotated_latitude_longitude\": shape (), type \"<i4\">\n",
      "time\n",
      "<HDF5 dataset \"time\": shape (10,), type \"<f8\">\n",
      "time_bnds\n",
      "<HDF5 dataset \"time_bnds\": shape (10, 2), type \"<f8\">\n"
     ]
    }
   ],
   "source": [
    "def visitor(member_name, obj):\n",
    "    print(member_name), print(obj)\n",
    "hds.visititems(visitor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cp {a_file} ./local.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"local.nc\" (mode r)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lhds = h5py.File('local.nc','r')\n",
    "lhds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnds\n",
      "<HDF5 dataset \"bnds\": shape (2,), type \">f4\">\n",
      "forecast_period\n",
      "<HDF5 dataset \"forecast_period\": shape (10,), type \"<f8\">\n",
      "forecast_period_bnds\n",
      "<HDF5 dataset \"forecast_period_bnds\": shape (10, 2), type \"<f8\">\n",
      "forecast_reference_time\n",
      "<HDF5 dataset \"forecast_reference_time\": shape (), type \"<f8\">\n",
      "grid_latitude\n",
      "<HDF5 dataset \"grid_latitude\": shape (219,), type \"<f4\">\n",
      "grid_longitude\n",
      "<HDF5 dataset \"grid_longitude\": shape (286,), type \"<f4\">\n",
      "precipitation_flux\n",
      "<HDF5 dataset \"precipitation_flux\": shape (10, 219, 286), type \"<f4\">\n",
      "rotated_latitude_longitude\n",
      "<HDF5 dataset \"rotated_latitude_longitude\": shape (), type \"<i4\">\n",
      "time\n",
      "<HDF5 dataset \"time\": shape (10,), type \"<f8\">\n",
      "time_bnds\n",
      "<HDF5 dataset \"time_bnds\": shape (10, 2), type \"<f8\">\n"
     ]
    }
   ],
   "source": [
    "lhds.visititems(visitor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"DIMENSION_LIST\": [[\"/time\"], [\"/grid_latitude\"], [\"/grid_longitude\"]], \"_Netcdf4Dimid\": 0, \"standard_name\": \"precipitation_flux\", \"units\": \"kg m-2 s-1\", \"um_stash_source\": \"m01s05i216\", \"cell_methods\": \"time: mean (interval: 1 hour)\", \"grid_mapping\": \"rotated_latitude_longitude\", \"coordinates\": \"forecast_period forecast_reference_time\"}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "class HDF5AttrsEncoder(json.JSONEncoder):\n",
    "    def __init__(self, file):\n",
    "        self.hd5file = file\n",
    "        \n",
    "    def default(self, obj):\n",
    "        if isinstance(obj,np.generic):\n",
    "            return obj.item()\n",
    "        if isinstance(obj, h5py.Reference):\n",
    "            return self.hd5file[obj].name\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            obj = obj.tolist()\n",
    "            return obj\n",
    "        if isinstance(obj, (np.bytes_, bytes)):\n",
    "            try:\n",
    "                return obj.decode('utf-8')\n",
    "            except UnicodeDecodeError:\n",
    "                print(f'couldn\\'t decode {obj}')\n",
    "                pass\n",
    "        \n",
    "        # Let the base class default method raise the TypeError\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "    \n",
    "json.dumps({k:v for k,v in flux.attrs.items()}, default=HDF5AttrsEncoder(flux.file).default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tiledb\n",
    "\n",
    "class DSBuilder():\n",
    "    def __init__(self, root, file):\n",
    "        self.groups = set()\n",
    "        self.root = root\n",
    "        self.file = file\n",
    "        \n",
    "        \n",
    "    def build(self):\n",
    "        self.handle_group('/', self.file)\n",
    "        self.file.visititems(self.visit)\n",
    "        \n",
    "        \n",
    "    def visit(self, member_name, obj):\n",
    "        # TODO Root attrs?\n",
    "        if isinstance(obj, h5py.Group):\n",
    "            self.handle_group(member_name, obj)\n",
    "        elif isinstance(obj, h5py.Dataset):\n",
    "            self.handle_ds(member_name, obj)\n",
    "        else:\n",
    "            raise RuntimeError(f\"What is this {obj}\")\n",
    "            \n",
    "    def handle_ds(self, ds_name, ds):\n",
    "        # TODO - what if ds visited before group?\n",
    "        ds_path = ds_name.rsplit('/',1)\n",
    "        if len(ds_path) == 1:\n",
    "            group = None\n",
    "            ds_base_name = ds_path[0]\n",
    "        elif ds_path[0].strip() == '':\n",
    "            group = None\n",
    "            ds_base_name = ds_path[1]\n",
    "        else:\n",
    "            group = ds_path[0]\n",
    "            ds_base_name = ds_path[1]\n",
    "            \n",
    "        print(f'make ds {ds_base_name} in group {group}')\n",
    "\n",
    "        if len(ds.shape) == 0:\n",
    "            self.create_scaler(group, ds_name, ds)\n",
    "        else:\n",
    "            self.create_array(group, ds_name, ds)\n",
    "        \n",
    "    def handel_var_attrs(self, ds_name, ds):\n",
    "        for k,v in  flux.attrs.items():\n",
    "            \n",
    "            print(f\"{k}:{v}\")\n",
    "        \n",
    "    def handle_group(self, group_name, group):\n",
    "        # TODO group attrs?\n",
    "        print(\"group name\", group_name)\n",
    "        path = os.path.join(self.root, group_name[1:] if group_name[0] == '/' else group_name )\n",
    "        os.makedirs(path, exist_ok=False)\n",
    "        tiledb.group_create(path)\n",
    "        print(f\"made_group {group_name} a {path}\")\n",
    "        with open(os.path.join(path,'attrs.json'),'w') as fp:\n",
    "            json.dump({k:v for k,v in group.attrs.items()}, fp, default=HDF5AttrsEncoder(self.file).default)\n",
    "        print(f'wrote group attrs for {group_name}')\n",
    "        \n",
    "    def __get_path(self, group, ds_name):\n",
    "        location = os.path.join(self.root, ds_name)\n",
    "        \n",
    "        if group and group is not \"/\":\n",
    "            location = os.path.join(self.root,group,ds_name)\n",
    "        return location\n",
    "        \n",
    "    def create_scaler(self, group, ds_name, ds):\n",
    "        # TODO: this is doggy!\n",
    "        location = self.__get_path(group, ds_name)\n",
    "        os.mkdir(location)\n",
    "        with open(os.path.join(location, \"value\"), 'w') as fp:\n",
    "            val = ds[()]\n",
    "            fp.write(str(val.item()))\n",
    "            \n",
    "        with open(os.path.join(location,'attrs.json'),'w') as fp:\n",
    "            json.dump({k:v for k,v in ds.attrs.items()}, fp,\n",
    "                      default=HDF5AttrsEncoder(self.file).default)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def create_array(self, group, ds_name, ds):\n",
    "        location = self.__get_path(group, ds_name)\n",
    "        os.mkdir(location)\n",
    "        \n",
    "        tile = 100\n",
    "        domain_indexs = [tiledb.Dim(name=f\"d{i}\", domain=(0,  np.iinfo(np.uint64).max-tile), tile=tile, dtype=np.uint64) for i in range(len(ds.shape))]\n",
    "        \n",
    "        data_type = {\n",
    "            \"float32\":np.float32,\n",
    "            \"float64\":np.float64,\n",
    "            \"int16\":np.int16,\n",
    "            \"int32\":np.int32,\n",
    "            \"int8\":np.int8,          \n",
    "        }[ds.dtype.name]\n",
    "\n",
    "            \n",
    "        # The array will be 4x4 with dimensions \"d1\" and \"d2\", with domain [1,4].\n",
    "        dom = tiledb.Domain(*domain_indexs)\n",
    "\n",
    "        # The array will be dense with a single attribute \"a\" so each (i,j) cell can store an integer.\n",
    "        schema = tiledb.ArraySchema(domain=dom, sparse=False,\n",
    "                                    attrs=[tiledb.Attr(name=ds_name, dtype=data_type)])\n",
    "\n",
    "        # Create the (empty) array on disk.\n",
    "        tiledb.DenseArray.create(location, schema)\n",
    "        \n",
    "        with tiledb.open(location,'w') as A:\n",
    "            for k, v in ds.attrs.items():\n",
    "                encoded_v = json.dumps(v, default=HDF5AttrsEncoder(self.file).default)\n",
    "                A.meta[k] = encoded_v\n",
    "            \n",
    "            data_domain = tuple([slice(0,i,None) for i in ds.shape])\n",
    "            data = ds[()]\n",
    "            \n",
    "            A[data_domain] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group name /\n",
      "made_group / a ./myds/\n",
      "wrote group attrs for /\n",
      "make ds bnds in group None\n",
      "make ds forecast_period in group None\n",
      "make ds forecast_period_bnds in group None\n",
      "make ds forecast_reference_time in group None\n",
      "make ds grid_latitude in group None\n",
      "make ds grid_longitude in group None\n",
      "make ds precipitation_flux in group None\n",
      "make ds rotated_latitude_longitude in group None\n",
      "make ds time in group None\n",
      "make ds time_bnds in group None\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./myds\n",
    "builder = DSBuilder('./myds',lhds )\n",
    "builder.build()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
