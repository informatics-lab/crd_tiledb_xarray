{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path = ['..'] + sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import shutil\n",
    "import iris\n",
    "import os\n",
    "import numpy as np\n",
    "import tiledb\n",
    "\n",
    "import json\n",
    "\n",
    "from tiledb_xarray.iris_writer import cubes_into_datasets,TileDBBuilder,TileDBAppender,linear_arr_extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import tiledb_xarray.iris_writer\n",
    "importlib.reload(tiledb_xarray.iris_writer)\n",
    "from tiledb_xarray.iris_writer import cubes_into_datasets,TileDBBuilder,TileDBAppender,linear_arr_extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(*args):\n",
    "    print(datetime.datetime.now(), *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/cssp-china/theo-6hrly-tile-db'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NC_SOURCE_DIR = \"/data/cssp-china/mini-dataset-24-01-19/nc/6hrly/\"\n",
    "files = [os.path.join(NC_SOURCE_DIR, f) for f in sorted(os.listdir(NC_SOURCE_DIR))][:1000]\n",
    "# part1_files, part2_files = files[:1], files[1:]\n",
    "# file_groups = [files[i:i+2] for i in range(0, len(files), 2)]\n",
    "\n",
    "TILEDB_PATH = os.path.abspath('/data/cssp-china/theo-6hrly-tile-db')\n",
    "TILEDB_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree(TILEDB_PATH, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-26 14:08:51.336239 load in iris\n"
     ]
    }
   ],
   "source": [
    "log('load in iris')\n",
    "first_file = files.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-26 11:41:41.198503 load in iris\n",
      "2020-02-26 11:41:44.362907 sort into domains\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tiledb_xarray.iris_writer.Dataset at 0x7fc1ec988990>,\n",
       " <tiledb_xarray.iris_writer.Dataset at 0x7fc1ec988d90>,\n",
       " <tiledb_xarray.iris_writer.Dataset at 0x7fc1efe896d0>,\n",
       " <tiledb_xarray.iris_writer.Dataset at 0x7fc1ecb58a90>,\n",
       " <tiledb_xarray.iris_writer.Dataset at 0x7fc1ec04ba10>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cubes = iris.load(first_file)\n",
    "log('sort into domains')\n",
    "datasets = cubes_into_datasets(cubes)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-26 11:41:46.724929 Build tiledb\n",
      "2020-02-26 11:41:53.236727 insert into m01s03i237_m01s03i245_m01s05i217_m01s05i217 shape (16, 219, 286)\n",
      "2020-02-26 11:42:07.461953 insert into m01s16i202_m01s16i203 shape (17, 14, 219, 286)\n",
      "2020-02-26 11:44:09.053879 insert into m01s12i202_m01s15i201_m01s15i202 shape (17, 14, 218, 286)\n",
      "2020-02-26 11:47:04.329094 insert into m01s00i024 shape (17, 219, 286)\n",
      "2020-02-26 11:47:15.661655 insert into m01s03i225_m01s03i226 shape (17, 218, 286)\n",
      "2020-02-26 11:47:25.587779 Built\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log('Build tiledb')\n",
    "builder = TileDBBuilder(datasets, TILEDB_PATH)\n",
    "builder.build()\n",
    "log('Built')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-26 11:52:20.311642 expand times\n",
      "2020-02-26 11:52:25.099528 Done time\n",
      "2020-02-26 11:52:27.238459 Done time\n",
      "2020-02-26 11:52:29.385417 Done time\n",
      "2020-02-26 11:52:31.412611 Done time\n",
      "2020-02-26 11:52:33.711201 Done time\n",
      "CPU times: user 84.3 ms, sys: 90.7 ms, total: 175 ms\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#  Extend in time....\n",
    "log('expand times')\n",
    "time_arrs = glob.glob(TILEDB_PATH+'/**/time')\n",
    "for arr in time_arrs:\n",
    "    linear_arr_extend(arr, 1000)\n",
    "    log('Done', os.path.basename(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.bag as db\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(file):\n",
    "    with dask.config.set(scheduler='single-threaded'):\n",
    "        cubes = iris.load(file)\n",
    "        datasets = cubes_into_datasets(cubes)\n",
    "        for dataset in datasets:\n",
    "            log(f'   add ds {dataset.key}')\n",
    "            appender = TileDBAppender(dataset, TILEDB_PATH)\n",
    "            appender.build()\n",
    "    return (file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion  = db.from_sequence(files[:1]).map(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-26 14:09:36.340973    add ds m01s03i237_m01s03i245_m01s05i217_m01s05i217\n",
      "2020-02-26 14:09:37.421434 insert into m01s03i237_m01s03i245_m01s05i217_m01s05i217 shape (40, 219, 286)\n",
      "2020-02-26 14:10:00.296306    add ds m01s16i202_m01s16i203\n",
      "2020-02-26 14:10:02.071419 insert into m01s16i202_m01s16i203 shape (40, 14, 219, 286)\n"
     ]
    }
   ],
   "source": [
    "conversion.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.dashboard.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "distributed.scheduler - INFO - Clear task state\n",
      "distributed.scheduler - INFO -   Scheduler at:  tcp://10.244.0.252:39299\n",
      "distributed.scheduler - INFO -   dashboard at:                     :8787\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='background-color: #f2f2f2; display: inline-block; padding: 10px; border: 1px solid #999999;'>\n",
       "  <h3>KubeCluster</h3>\n",
       "  <ul>\n",
       "    <li><b>Dashboard: </b><a href='/user/tam203/proxy/8787/status' target='_blank'>/user/tam203/proxy/8787/status</a>\n",
       "  </ul>\n",
       "</div>\n"
      ],
      "text/plain": [
       "KubeCluster('tcp://10.244.0.252:39299', workers=0, threads=0, memory=0 B)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Receive client connection: Client-607db8f0-589d-11ea-8035-26577c477f88\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.244.0.252:39299</li>\n",
       "  <li><b>Dashboard: </b><a href='/user/tam203/proxy/8787/status' target='_blank'>/user/tam203/proxy/8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.244.0.252:39299' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.0.253:40679', name: 17, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.0.253:40679\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.0.254:44241', name: 42, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.0.254:44241\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.0.3:36907', name: 25, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.0.3:36907\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.9.195:35889', name: 20, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.9.195:35889\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.9.194:36239', name: 30, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.9.194:36239\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.9.196:38469', name: 41, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.9.196:38469\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.0.4:40225', name: 16, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.0.4:40225\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.9.197:40555', name: 40, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.9.197:40555\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.0.6:43979', name: 29, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.0.6:43979\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.9.198:34827', name: 12, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.9.198:34827\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.0.8:34441', name: 33, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.0.8:34441\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.9.199:35469', name: 21, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.9.199:35469\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.0.10:38973', name: 3, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.0.10:38973\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.9.200:42003', name: 8, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.9.200:42003\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.0.11:43657', name: 4, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.0.11:43657\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.9.201:39569', name: 36, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.9.201:39569\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.9.202:37473', name: 48, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.9.202:37473\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client, progress\n",
    "import distributed\n",
    "import dask\n",
    "from dask_kubernetes import KubeCluster\n",
    "from dask import bag as db\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "cluster = KubeCluster()\n",
    "cluster.scale_up(50)\n",
    "display(cluster)\n",
    "# Connect dask to the cluster\n",
    "client = distributed.Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-26 11:28:30.352205 load rest of the cubes \n",
      "2020-02-26 11:28:30.352610 add file 0\n",
      "2020-02-26 11:28:35.314672    add ds m01s03i237_m01s03i245_m01s05i217_m01s05i217\n",
      "2020-02-26 11:28:35.512889 insert into m01s03i237_m01s03i245_m01s05i217_m01s05i217 shape (40, 219, 286)\n",
      "2020-02-26 11:28:46.124416    add ds m01s16i202_m01s16i203\n",
      "2020-02-26 11:28:47.083419 insert into m01s16i202_m01s16i203 shape (40, 14, 219, 286)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4229f0df4ea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mappender\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTileDBAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTILEDB_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mappender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jovyan/crd_tiledb_xarray/tiledb_xarray/iris_writer.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_offsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jovyan/crd_tiledb_xarray/tiledb_xarray/iris_writer.py\u001b[0m in \u001b[0;36m_insert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    221\u001b[0m         )\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtiledb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_offset_of_coord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtiledb_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Append the rest\n",
    "# # for file in part2_files:\n",
    "# log('load rest of the cubes ')\n",
    "# for i, file in enumerate(files):\n",
    "#     log(f\"add file {i}\")\n",
    "#     cubes = iris.load(file)\n",
    "#     datasets = cubes_into_datasets(cubes)\n",
    "#     for dataset in datasets:\n",
    "#         log(f'   add ds {dataset.key}')\n",
    "\n",
    "#         appender = TileDBAppender(dataset, TILEDB_PATH)\n",
    "#         appender.build()\n",
    "\n",
    "\n",
    "# log(\"Fin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cfa32f997bb4f42844f38ca7cd97860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "conversion = conversion.persist()  # start computation in the background\n",
    "progress(conversion)      # watch progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.7.10\n",
      "  latest version: 4.8.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /root/my-conda-envs/py3.7\n",
      "\n",
      "  added / updated specs:\n",
      "    - ipywidgets\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    bleach-3.1.0               |           py37_0         220 KB\n",
      "    ca-certificates-2020.1.1   |                0         125 KB\n",
      "    certifi-2019.11.28         |           py37_0         153 KB\n",
      "    defusedxml-0.6.0           |             py_0          23 KB\n",
      "    entrypoints-0.3            |           py37_0          12 KB\n",
      "    gmp-6.1.2                  |       h6c8ec71_1         514 KB\n",
      "    importlib_metadata-1.5.0   |           py37_0          48 KB\n",
      "    ipywidgets-7.5.1           |             py_0         107 KB\n",
      "    jsonschema-3.2.0           |           py37_0          95 KB\n",
      "    mistune-0.8.4              |   py37h7b6447c_0          55 KB\n",
      "    nbconvert-5.6.1            |           py37_0         459 KB\n",
      "    nbformat-5.0.4             |             py_0          89 KB\n",
      "    notebook-6.0.3             |           py37_0         4.0 MB\n",
      "    openssl-1.1.1d             |       h7b6447c_4         2.5 MB\n",
      "    pandoc-2.2.3.2             |                0        14.0 MB\n",
      "    pandocfilters-1.4.2        |           py37_1          13 KB\n",
      "    prometheus_client-0.7.1    |             py_0          42 KB\n",
      "    pyrsistent-0.15.7          |   py37h7b6447c_0          93 KB\n",
      "    send2trash-1.5.0           |           py37_0          16 KB\n",
      "    terminado-0.8.3            |           py37_0          26 KB\n",
      "    testpath-0.4.4             |             py_0          88 KB\n",
      "    webencodings-0.5.1         |           py37_1          19 KB\n",
      "    widgetsnbextension-3.5.1   |           py37_0         862 KB\n",
      "    zipp-2.2.0                 |             py_0          12 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        23.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  bleach             pkgs/main/linux-64::bleach-3.1.0-py37_0\n",
      "  defusedxml         pkgs/main/noarch::defusedxml-0.6.0-py_0\n",
      "  entrypoints        pkgs/main/linux-64::entrypoints-0.3-py37_0\n",
      "  gmp                pkgs/main/linux-64::gmp-6.1.2-h6c8ec71_1\n",
      "  importlib_metadata pkgs/main/linux-64::importlib_metadata-1.5.0-py37_0\n",
      "  ipywidgets         pkgs/main/noarch::ipywidgets-7.5.1-py_0\n",
      "  jsonschema         pkgs/main/linux-64::jsonschema-3.2.0-py37_0\n",
      "  mistune            pkgs/main/linux-64::mistune-0.8.4-py37h7b6447c_0\n",
      "  nbconvert          pkgs/main/linux-64::nbconvert-5.6.1-py37_0\n",
      "  nbformat           pkgs/main/noarch::nbformat-5.0.4-py_0\n",
      "  notebook           pkgs/main/linux-64::notebook-6.0.3-py37_0\n",
      "  pandoc             pkgs/main/linux-64::pandoc-2.2.3.2-0\n",
      "  pandocfilters      pkgs/main/linux-64::pandocfilters-1.4.2-py37_1\n",
      "  prometheus_client  pkgs/main/noarch::prometheus_client-0.7.1-py_0\n",
      "  pyrsistent         pkgs/main/linux-64::pyrsistent-0.15.7-py37h7b6447c_0\n",
      "  send2trash         pkgs/main/linux-64::send2trash-1.5.0-py37_0\n",
      "  terminado          pkgs/main/linux-64::terminado-0.8.3-py37_0\n",
      "  testpath           pkgs/main/noarch::testpath-0.4.4-py_0\n",
      "  webencodings       pkgs/main/linux-64::webencodings-0.5.1-py37_1\n",
      "  widgetsnbextension pkgs/main/linux-64::widgetsnbextension-3.5.1-py37_0\n",
      "  zipp               pkgs/main/noarch::zipp-2.2.0-py_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2019.11.~ --> pkgs/main::ca-certificates-2020.1.1-0\n",
      "  openssl            conda-forge::openssl-1.1.1d-h516909a_0 --> pkgs/main::openssl-1.1.1d-h7b6447c_4\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi                                       conda-forge --> pkgs/main\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "nbconvert-5.6.1      | 459 KB    | ##################################### | 100% \n",
      "importlib_metadata-1 | 48 KB     | ##################################### | 100% \n",
      "pandocfilters-1.4.2  | 13 KB     | ##################################### | 100% \n",
      "openssl-1.1.1d       | 2.5 MB    | ##################################### | 100% \n",
      "entrypoints-0.3      | 12 KB     | ##################################### | 100% \n",
      "testpath-0.4.4       | 88 KB     | ##################################### | 100% \n",
      "ca-certificates-2020 | 125 KB    | ##################################### | 100% \n",
      "send2trash-1.5.0     | 16 KB     | ##################################### | 100% \n",
      "notebook-6.0.3       | 4.0 MB    | ####################################4 |  99% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.0.10:34695', name: 3, memory: 7, processing: 11>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.0.10:34695\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.0.10:33931', name: 3, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.0.10:33931\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook-6.0.3       | 4.0 MB    | ##################################### | 100% \n",
      "zipp-2.2.0           | 12 KB     | ##################################### | 100% \n",
      "webencodings-0.5.1   | 19 KB     | ##################################### | 100% \n",
      "pyrsistent-0.15.7    | 93 KB     | ##################################### | 100% \n",
      "widgetsnbextension-3 | 862 KB    | ##################################### | 100% \n",
      "jsonschema-3.2.0     | 95 KB     | ##################################### | 100% \n",
      "gmp-6.1.2            | 514 KB    | ##################################### | 100% \n",
      "nbformat-5.0.4       | 89 KB     | ##################################### | 100% \n",
      "certifi-2019.11.28   | 153 KB    | ##################################### | 100% \n",
      "mistune-0.8.4        | 55 KB     | ##################################### | 100% \n",
      "pandoc-2.2.3.2       | 14.0 MB   | ###############1                      |  41% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.2.6:45901', name: 9, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.2.6:45901\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.2.8:42285', name: 14, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.2.8:42285\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.2.9:41315', name: 43, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.2.9:41315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandoc-2.2.3.2       | 14.0 MB   | ################2                     |  44% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.2.7:41995', name: 11, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.2.7:41995\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandoc-2.2.3.2       | 14.0 MB   | ####################################1 |  98% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.1.13:33451', name: 34, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.1.13:33451\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.1.6:40013', name: 31, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.1.6:40013\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.1.7:46417', name: 44, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.1.7:46417\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.1.14:43765', name: 5, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.1.14:43765\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.1.10:38963', name: 38, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.1.10:38963\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.1.8:41967', name: 49, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.1.8:41967\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.1.9:38379', name: 46, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.1.9:38379\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.1.11:42765', name: 26, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.1.11:42765\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.1.15:35435', name: 32, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.1.15:35435\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.1.12:42471', name: 35, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.1.12:42471\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.2.10:44669', name: 18, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.2.10:44669\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.2.11:36309', name: 13, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.2.11:36309\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.2.12:34073', name: 0, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.2.12:34073\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.2.13:35729', name: 37, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.2.13:35729\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.2.14:35423', name: 23, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.2.14:35423\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.2.15:45101', name: 22, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.2.15:45101\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.0.10:33931', name: 3, memory: 3, processing: 1>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.0.10:33931\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.0.10:40913', name: 3, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.0.10:40913\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandoc-2.2.3.2       | 14.0 MB   | ##################################### | 100% \n",
      "terminado-0.8.3      | 26 KB     | ##################################### | 100% \n",
      "defusedxml-0.6.0     | 23 KB     | ##################################### | 100% \n",
      "bleach-3.1.0         | 220 KB    |                                       |   0% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.4.8:44571', name: 27, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.4.8:44571\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.4.7:44305', name: 6, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.4.7:44305\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.4.6:36875', name: 47, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.4.6:36875\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.3.8:34043', name: 10, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.3.8:34043\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.3.6:43243', name: 24, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.3.6:43243\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.3.9:32831', name: 1, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.3.9:32831\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.3.7:43207', name: 28, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.3.7:43207\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.3.10:39635', name: 45, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.3.10:39635\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.3.11:44379', name: 19, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.3.11:44379\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.3.12:36743', name: 7, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.3.12:36743\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.3.13:33925', name: 2, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.3.13:33925\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.3.14:39183', name: 15, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.3.14:39183\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.244.3.15:39201', name: 39, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.244.3.15:39201\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleach-3.1.0         | 220 KB    | ##################################### | 100% \n",
      "prometheus_client-0. | 42 KB     | ##################################### | 100% \n",
      "ipywidgets-7.5.1     | 107 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install ipywidgets -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Scheduler closing...\n",
      "distributed.scheduler - INFO - Scheduler closing all comms\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.0.253:40679', name: 17, memory: 1, processing: 1>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.0.253:40679\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.0.254:44241', name: 42, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.0.254:44241\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.0.3:36907', name: 25, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.0.3:36907\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.0.4:40225', name: 16, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.0.4:40225\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.0.6:43979', name: 29, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.0.6:43979\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.0.8:34441', name: 33, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.0.8:34441\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.9.195:35889', name: 20, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.9.195:35889\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.9.196:38469', name: 41, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.9.196:38469\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.9.198:34827', name: 12, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.9.198:34827\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.9.194:36239', name: 30, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.9.194:36239\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.0.11:43657', name: 4, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.0.11:43657\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.1.13:33451', name: 34, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.1.13:33451\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.1.10:38963', name: 38, memory: 1, processing: 1>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.1.10:38963\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.1.7:46417', name: 44, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.1.7:46417\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.1.14:43765', name: 5, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.1.14:43765\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.1.9:38379', name: 46, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.1.9:38379\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.1.6:40013', name: 31, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.1.6:40013\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.1.12:42471', name: 35, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.1.12:42471\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.9.202:37473', name: 48, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.9.202:37473\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.1.8:41967', name: 49, memory: 0, processing: 1>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.1.8:41967\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.9.200:42003', name: 8, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.9.200:42003\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.2.9:41315', name: 43, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.2.9:41315\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.2.10:44669', name: 18, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.2.10:44669\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.9.201:39569', name: 36, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.9.201:39569\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.9.199:35469', name: 21, memory: 0, processing: 1>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.9.199:35469\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.244.0.10:40913', name: 3, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.244.0.10:40913\n",
      "distributed.scheduler - INFO - Plugin failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/my-conda-envs/py3.7/lib/python3.7/site-packages/distributed/scheduler.py\", line 4645, in transition\n",
      "    plugin.transition(key, start, finish2, *args, **kwargs)\n",
      "  File \"/root/my-conda-envs/py3.7/lib/python3.7/site-packages/distributed/diagnostics/progress.py\", line 215, in transition\n",
      "    self.stop(exception=True)\n",
      "  File \"/root/my-conda-envs/py3.7/lib/python3.7/site-packages/distributed/diagnostics/progress.py\", line 126, in stop\n",
      "    self.extra.update({\"exception\": self.scheduler.exceptions[key], \"key\": key})\n",
      "  File \"/root/my-conda-envs/py3.7/lib/python3.7/site-packages/distributed/scheduler.py\", line 890, in __getitem__\n",
      "    v = self._accessor(self._states[key])\n",
      "KeyError: None\n",
      "tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7f12f1ea2190>>, <Task finished coro=<MultiProgressBar.listen() done, defined at /root/my-conda-envs/py3.7/lib/python3.7/site-packages/distributed/diagnostics/progressbar.py:238> exception=TypeError(\"'NoneType' object is not subscriptable\")>)\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/my-conda-envs/py3.7/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/root/my-conda-envs/py3.7/lib/python3.7/site-packages/tornado/ioloop.py\", line 767, in _discard_future_result\n",
      "    future.result()\n",
      "  File \"/root/my-conda-envs/py3.7/lib/python3.7/site-packages/distributed/diagnostics/progressbar.py\", line 278, in listen\n",
      "    self.status = response[\"status\"]\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "distributed.client - ERROR - Failed to reconnect to scheduler after 10.00 seconds, closing client\n",
      "_GatheringFuture exception was never retrieved\n",
      "future: <_GatheringFuture finished exception=CancelledError()>\n",
      "concurrent.futures._base.CancelledError\n"
     ]
    }
   ],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
