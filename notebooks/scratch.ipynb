{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitpy37condaa9cb9add6fde46108b059d81152d2f41",
   "display_name": "Python 3.7.6 64-bit ('py3.7': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path = [os.path.abspath(os.path.join(os.curdir,'..'))] + sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tiledb_xarray import TileDBDataSetBuilder\n",
    "import netCDF4\n",
    "import h5py\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib \n",
    "import tiledb_xarray\n",
    "import tiledb_xarray.hdf5_tiledb_writer \n",
    "importlib.reload(tiledb_xarray)\n",
    "importlib.reload(tiledb_xarray.hdf5_tiledb_writer)\n",
    "from  tiledb_xarray import get_data_datasets_and_others\n",
    "from tiledb_xarray.hdf5_tiledb_writer import TileDBDataSetBuilderDimsInAttrs,HDF5AttrsEncoder, DIM_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.abspath(os.path.join(os.curdir,'..', 'data'))\n",
    "in_file = os.path.join(DATA_DIR, \"apepda.pc51150.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_file = h5py.File(in_file,'r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding just data arrays by excluding bnds, dims, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Data:\n"
    },
    {
     "data": {
      "text/plain": "{'air_pressure_at_sea_level',\n 'air_temperature',\n 'cloud_area_fraction',\n 'relative_humidity',\n 'specific_humidity',\n 'surface_air_pressure',\n 'surface_downwelling_longwave_flux_in_air',\n 'surface_downwelling_shortwave_flux_in_air'}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Other:\n"
    },
    {
     "data": {
      "text/plain": "{'bnds',\n 'forecast_period',\n 'forecast_period_0',\n 'forecast_period_0_bnds',\n 'forecast_reference_time',\n 'grid_latitude',\n 'grid_longitude',\n 'height',\n 'rotated_latitude_longitude',\n 'time',\n 'time_0',\n 'time_0_bnds'}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "data_ds, other_ds = get_data_datasets_and_others(open_file)\n",
    "\n",
    "print(\"Data:\")\n",
    "display(data_ds)\n",
    "\n",
    "print(\"Other:\")\n",
    "display(other_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find shared domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'[[\"/time_0\"], [\"/grid_latitude\"], [\"/grid_longitude\"]]__(32, 219, 286)': ['cloud_area_fraction',\n  'surface_downwelling_longwave_flux_in_air',\n  'surface_downwelling_shortwave_flux_in_air'],\n '[[\"/time\"], [\"/grid_latitude\"], [\"/grid_longitude\"]]__(33, 219, 286)': ['relative_humidity',\n  'specific_humidity',\n  'air_pressure_at_sea_level',\n  'air_temperature',\n  'surface_air_pressure']}"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude = set()\n",
    "all_items = set()\n",
    "open_file.visititems(partial(excluder, exclude))\n",
    "open_file.visit(lambda x: all_items.add(x))\n",
    "\n",
    "\n",
    "\n",
    "data_sets = all_items - exclude\n",
    "\n",
    "\n",
    "domains = {}\n",
    "for ds_name in data_sets:\n",
    "    ds = open_file[ds_name]\n",
    "    key = json.dumps(ds.attrs[DIM_KEY], default=HDF5AttrsEncoder(ds.file).default) + \"__\" + str(ds.shape)\n",
    "    dom = domains.get(key,[])\n",
    "    dom.append(ds_name)\n",
    "    domains[key] = dom\n",
    "\n",
    "domains\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build ds with Multi phonomeno "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "importlib.reload(tiledb_xarray)\n",
    "importlib.reload(tiledb_xarray.hdf5_tiledb_writer)\n",
    "from tiledb_xarray.hdf5_tiledb_writer import  MultiPhonomBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "diffs = np.diff([1,2,3,4,5])\n",
    "all([diffs[i] == diffs[i-1] for i in range(1, len(diffs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'/time_0'"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "open_file['time_0'].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "True\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\n"
    }
   ],
   "source": [
    "for i, val in enumerate(open_file['time_0'][()]):\n",
    "    print(f\"{3*i + -1043134.5 == val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "group <HDF5 file \"apepda.pc51150.nc\" (mode r)> type <class 'h5py._hl.files.File'>\ngroup name /\nmade_group / at /Users/theo/repos/crd_tiledb_xarray/data/multi_phonom/\nwrote group attrs for /\ncreate multi for [[time_0][grid_latitude][grid_longitude]] at /Users/theo/repos/crd_tiledb_xarray/data/multi_phonom/[[time_0][grid_latitude][grid_longitude]]\ntime_0 ['time', 'time_0']\ntime_0\nis dynamic\ncoord time_0 == 3.0 x i + -1043134.5\ngrid_latitude ['time', 'time_0']\ngrid_latitude\ngrid_longitude ['time', 'time_0']\ngrid_longitude\n"
    },
    {
     "ename": "TileDBError",
     "evalue": "[TileDB::ArraySchema] Error: Array schema check failed; Attributes and dimensions must have unique names",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTileDBError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-93ad618053ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm -rf {out} '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbuilder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiPhonomBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_coords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'time_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repos/crd_tiledb_xarray/tiledb_xarray/hdf5_tiledb_writer.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_sets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdomains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mdomain_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_multi_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_dom_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_sets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dynamic_dim_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/crd_tiledb_xarray/tiledb_xarray/hdf5_tiledb_writer.py\u001b[0m in \u001b[0;36mcreate_multi_array\u001b[0;34m(self, domain_name, data_sets)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         schema = tiledb.ArraySchema(domain=dom, sparse=False,\n\u001b[0;32m--> 225\u001b[0;31m                                     attrs=attrs)\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# Create the (empty) array on disk.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtiledb/libtiledb.pyx\u001b[0m in \u001b[0;36mtiledb.libtiledb.ArraySchema.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mtiledb/libtiledb.pyx\u001b[0m in \u001b[0;36mtiledb.libtiledb._raise_ctx_err\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mtiledb/libtiledb.pyx\u001b[0m in \u001b[0;36mtiledb.libtiledb._raise_tiledb_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTileDBError\u001b[0m: [TileDB::ArraySchema] Error: Array schema check failed; Attributes and dimensions must have unique names"
     ]
    }
   ],
   "source": [
    "out = DATA_DIR + '/multi_phonom'\n",
    "!rm -rf {out} \n",
    "builder = MultiPhonomBuilder(out, open_file, dynamic_coords=['time', 'time_0'])\n",
    "builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[-10:-1,1,1]\n",
    "A.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((0, 32), (0, 218), (0, 285))"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "OrderedDict([('relative_humidity', array([[[100.]],\n\n       [[100.]],\n\n       [[100.]]], dtype=float32)), ('air_temperature', array([[[263.58997]],\n\n       [[261.53253]],\n\n       [[260.20972]]], dtype=float32)), ('surface_air_pressure', array([[[100834.]],\n\n       [[100956.]],\n\n       [[101078.]]], dtype=float32)), ('air_pressure_at_sea_level', array([[[101628.]],\n\n       [[101752.]],\n\n       [[101877.]]], dtype=float32)), ('specific_humidity', array([[[0.00167337]],\n\n       [[0.00139362]],\n\n       [[0.00123442]]], dtype=float32))])\nOrderedDict([('relative_humidity', array([nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)), ('air_temperature', array([nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)), ('surface_air_pressure', array([nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)), ('air_pressure_at_sea_level', array([nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)), ('specific_humidity', array([nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32))])\n"
    }
   ],
   "source": [
    "import tiledb\n",
    "A =  tiledb.open('/Users/theo/repos/crd_tiledb_xarray/data/multi_phonom/[[time][grid_latitude][grid_longitude]]','r')\n",
    "display(A.nonempty_domain())\n",
    "print(A[0:3,0:1,2:3])\n",
    "print(A[-10:-1,1,1])\n",
    "A.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a DS with the TileDBDataSetBuilderDimsInAttrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = ds - exclue\n",
    "data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DS = \"specific_humidity\"\n",
    "ds = open_file[MY_DS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiledb_xarray.hdf5_tiledb_writer\n",
    "\n",
    "importlib.reload(tiledb_xarray.hdf5_tiledb_writer)\n",
    "from  tiledb_xarray.hdf5_tiledb_writer import HDF5DSEncoder\n",
    "from tiledb_xarray.hdf5_tiledb_writer import TileDBDataSetBuilderDimsInAttrs,HDF5AttrsEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Exclude: {'height', 'time_0_bnds', 'forecast_period', 'time', 'forecast_reference_time', 'grid_longitude', 'time_0', 'grid_latitude', 'forecast_period_0', 'forecast_period_0_bnds', 'bnds'}\ngroup <HDF5 file \"apepda.pc51150.nc\" (mode r)> type <class 'h5py._hl.files.File'>\ngroup name /\nmade_group / at /Users/theo/repos/crd_tiledb_xarray/data/new-tiledb/\nwrote group attrs for /\nair_pressure_at_sea_level not in {'height', 'time_0_bnds', 'forecast_period', 'time', 'forecast_reference_time', 'grid_longitude', 'time_0', 'grid_latitude', 'forecast_period_0', 'forecast_period_0_bnds', 'bnds'}\nmake ds air_pressure_at_sea_level in group None\nair_temperature not in {'height', 'time_0_bnds', 'forecast_period', 'time', 'forecast_reference_time', 'grid_longitude', 'time_0', 'grid_latitude', 'forecast_period_0', 'forecast_period_0_bnds', 'bnds'}\nmake ds air_temperature in group None\ncloud_area_fraction not in {'height', 'time_0_bnds', 'forecast_period', 'time', 'forecast_reference_time', 'grid_longitude', 'time_0', 'grid_latitude', 'forecast_period_0', 'forecast_period_0_bnds', 'bnds'}\nmake ds cloud_area_fraction in group None\nrelative_humidity not in {'height', 'time_0_bnds', 'forecast_period', 'time', 'forecast_reference_time', 'grid_longitude', 'time_0', 'grid_latitude', 'forecast_period_0', 'forecast_period_0_bnds', 'bnds'}\nmake ds relative_humidity in group None\nrotated_latitude_longitude not in {'height', 'time_0_bnds', 'forecast_period', 'time', 'forecast_reference_time', 'grid_longitude', 'time_0', 'grid_latitude', 'forecast_period_0', 'forecast_period_0_bnds', 'bnds'}\nmake ds rotated_latitude_longitude in group None\nspecific_humidity not in {'height', 'time_0_bnds', 'forecast_period', 'time', 'forecast_reference_time', 'grid_longitude', 'time_0', 'grid_latitude', 'forecast_period_0', 'forecast_period_0_bnds', 'bnds'}\nmake ds specific_humidity in group None\nsurface_air_pressure not in {'height', 'time_0_bnds', 'forecast_period', 'time', 'forecast_reference_time', 'grid_longitude', 'time_0', 'grid_latitude', 'forecast_period_0', 'forecast_period_0_bnds', 'bnds'}\nmake ds surface_air_pressure in group None\nsurface_downwelling_longwave_flux_in_air not in {'height', 'time_0_bnds', 'forecast_period', 'time', 'forecast_reference_time', 'grid_longitude', 'time_0', 'grid_latitude', 'forecast_period_0', 'forecast_period_0_bnds', 'bnds'}\nmake ds surface_downwelling_longwave_flux_in_air in group None\nsurface_downwelling_shortwave_flux_in_air not in {'height', 'time_0_bnds', 'forecast_period', 'time', 'forecast_reference_time', 'grid_longitude', 'time_0', 'grid_latitude', 'forecast_period_0', 'forecast_period_0_bnds', 'bnds'}\nmake ds surface_downwelling_shortwave_flux_in_air in group None\n"
    }
   ],
   "source": [
    "OUT = DATA_DIR+\"/new-tiledb\"\n",
    "! rm -r {OUT}\n",
    "builder = TileDBDataSetBuilderDimsInAttrs(OUT, ds.file)\n",
    "builder.build()\n",
    "builder.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiledb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tiledb.open(OUT+'/cloud_area_fraction','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.nonempty_domain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k:json.loads(v) for k,v in A.meta.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Try group datasets into domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## NetCDF lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<class 'netCDF4._netCDF4.Dataset'>\nroot group (NETCDF4 data model, file format HDF5):\n    source: Data from Met Office Unified Model\n    Conventions: CF-1.5\n    dimensions(sizes): time(33), grid_latitude(219), grid_longitude(286), time_0(32), bnds(2)\n    variables(dimensions): float32 \u001b[4mair_pressure_at_sea_level\u001b[0m(time,grid_latitude,grid_longitude), int32 \u001b[4mrotated_latitude_longitude\u001b[0m(), float64 \u001b[4mtime\u001b[0m(time), float32 \u001b[4mgrid_latitude\u001b[0m(grid_latitude), float32 \u001b[4mgrid_longitude\u001b[0m(grid_longitude), float64 \u001b[4mforecast_period\u001b[0m(time), float64 \u001b[4mforecast_reference_time\u001b[0m(), float32 \u001b[4mair_temperature\u001b[0m(time,grid_latitude,grid_longitude), float64 \u001b[4mheight\u001b[0m(), float32 \u001b[4mcloud_area_fraction\u001b[0m(time_0,grid_latitude,grid_longitude), float64 \u001b[4mtime_0\u001b[0m(time_0), float64 \u001b[4mtime_0_bnds\u001b[0m(time_0,bnds), float64 \u001b[4mforecast_period_0\u001b[0m(time_0), float64 \u001b[4mforecast_period_0_bnds\u001b[0m(time_0,bnds), float32 \u001b[4mrelative_humidity\u001b[0m(time,grid_latitude,grid_longitude), float32 \u001b[4mspecific_humidity\u001b[0m(time,grid_latitude,grid_longitude), float32 \u001b[4msurface_air_pressure\u001b[0m(time,grid_latitude,grid_longitude), float32 \u001b[4msurface_downwelling_longwave_flux_in_air\u001b[0m(time_0,grid_latitude,grid_longitude), float32 \u001b[4msurface_downwelling_shortwave_flux_in_air\u001b[0m(time_0,grid_latitude,grid_longitude)\n    groups: "
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncds = netCDF4.Dataset(in_file)\n",
    "ncds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{<class 'netCDF4._netCDF4.Variable'>\n float32 air_pressure_at_sea_level(time, grid_latitude, grid_longitude)\n     standard_name: air_pressure_at_sea_level\n     units: Pa\n     um_stash_source: m01s16i222\n     grid_mapping: rotated_latitude_longitude\n     coordinates: forecast_period forecast_reference_time\n unlimited dimensions: \n current shape = (33, 219, 286)\n filling on, default _FillValue of 9.969209968386869e+36 used,\n <class 'netCDF4._netCDF4.Variable'>\n float32 air_temperature(time, grid_latitude, grid_longitude)\n     standard_name: air_temperature\n     units: K\n     um_stash_source: m01s03i236\n     grid_mapping: rotated_latitude_longitude\n     coordinates: forecast_period forecast_reference_time height\n unlimited dimensions: \n current shape = (33, 219, 286)\n filling on, default _FillValue of 9.969209968386869e+36 used,\n <class 'netCDF4._netCDF4.Variable'>\n float32 cloud_area_fraction(time_0, grid_latitude, grid_longitude)\n     standard_name: cloud_area_fraction\n     units: 1\n     um_stash_source: m01s02i204\n     cell_methods: time_0: mean (interval: 3 hour)\n     grid_mapping: rotated_latitude_longitude\n     coordinates: forecast_period_0 forecast_reference_time\n unlimited dimensions: \n current shape = (32, 219, 286)\n filling on, default _FillValue of 9.969209968386869e+36 used,\n <class 'netCDF4._netCDF4.Variable'>\n float32 grid_latitude(grid_latitude)\n     axis: Y\n     units: degrees\n     standard_name: grid_latitude\n unlimited dimensions: \n current shape = (219,)\n filling on, default _FillValue of 9.969209968386869e+36 used,\n <class 'netCDF4._netCDF4.Variable'>\n float32 grid_longitude(grid_longitude)\n     axis: X\n     units: degrees\n     standard_name: grid_longitude\n unlimited dimensions: \n current shape = (286,)\n filling on, default _FillValue of 9.969209968386869e+36 used,\n <class 'netCDF4._netCDF4.Variable'>\n float32 relative_humidity(time, grid_latitude, grid_longitude)\n     standard_name: relative_humidity\n     units: %\n     um_stash_source: m01s03i245\n     grid_mapping: rotated_latitude_longitude\n     coordinates: forecast_period forecast_reference_time height\n unlimited dimensions: \n current shape = (33, 219, 286)\n filling on, default _FillValue of 9.969209968386869e+36 used,\n <class 'netCDF4._netCDF4.Variable'>\n float32 specific_humidity(time, grid_latitude, grid_longitude)\n     standard_name: specific_humidity\n     units: 1\n     um_stash_source: m01s03i237\n     grid_mapping: rotated_latitude_longitude\n     coordinates: forecast_period forecast_reference_time height\n unlimited dimensions: \n current shape = (33, 219, 286)\n filling on, default _FillValue of 9.969209968386869e+36 used,\n <class 'netCDF4._netCDF4.Variable'>\n float32 surface_air_pressure(time, grid_latitude, grid_longitude)\n     standard_name: surface_air_pressure\n     units: Pa\n     um_stash_source: m01s00i001\n     grid_mapping: rotated_latitude_longitude\n     coordinates: forecast_period forecast_reference_time\n unlimited dimensions: \n current shape = (33, 219, 286)\n filling on, default _FillValue of 9.969209968386869e+36 used,\n <class 'netCDF4._netCDF4.Variable'>\n float32 surface_downwelling_longwave_flux_in_air(time_0, grid_latitude, grid_longitude)\n     standard_name: surface_downwelling_longwave_flux_in_air\n     units: W m-2\n     um_stash_source: m01s02i207\n     cell_methods: time_0: mean (interval: 3 hour)\n     grid_mapping: rotated_latitude_longitude\n     coordinates: forecast_period_0 forecast_reference_time\n unlimited dimensions: \n current shape = (32, 219, 286)\n filling on, default _FillValue of 9.969209968386869e+36 used,\n <class 'netCDF4._netCDF4.Variable'>\n float32 surface_downwelling_shortwave_flux_in_air(time_0, grid_latitude, grid_longitude)\n     standard_name: surface_downwelling_shortwave_flux_in_air\n     units: W m-2\n     um_stash_source: m01s01i235\n     cell_methods: time_0: mean (interval: 3 hour)\n     grid_mapping: rotated_latitude_longitude\n     coordinates: forecast_period_0 forecast_reference_time\n unlimited dimensions: \n current shape = (32, 219, 286)\n filling on, default _FillValue of 9.969209968386869e+36 used,\n <class 'netCDF4._netCDF4.Variable'>\n float64 forecast_period(time)\n     units: hours\n     standard_name: forecast_period\n unlimited dimensions: \n current shape = (33,)\n filling on, default _FillValue of 9.969209968386869e+36 used,\n <class 'netCDF4._netCDF4.Variable'>\n float64 forecast_period_0(time_0)\n     bounds: forecast_period_0_bnds\n     units: hours\n     standard_name: forecast_period\n unlimited dimensions: \n current shape = (32,)\n filling on, default _FillValue of 9.969209968386869e+36 used,\n <class 'netCDF4._netCDF4.Variable'>\n float64 forecast_period_0_bnds(time_0, bnds)\n unlimited dimensions: \n current shape = (32, 2)\n filling on, default _FillValue of 9.969209968386869e+36 used,\n <class 'netCDF4._netCDF4.Variable'>\n float64 forecast_reference_time()\n     units: hours since 1970-01-01 00:00:00\n     standard_name: forecast_reference_time\n     calendar: gregorian\n unlimited dimensions: \n current shape = ()\n filling on, default _FillValue of 9.969209968386869e+36 used,\n <class 'netCDF4._netCDF4.Variable'>\n float64 height()\n     units: m\n     standard_name: height\n     positive: up\n unlimited dimensions: \n current shape = ()\n filling on, default _FillValue of 9.969209968386869e+36 used,\n <class 'netCDF4._netCDF4.Variable'>\n float64 time(time)\n     axis: T\n     units: hours since 1970-01-01 00:00:00\n     standard_name: time\n     calendar: gregorian\n unlimited dimensions: \n current shape = (33,)\n filling on, default _FillValue of 9.969209968386869e+36 used,\n <class 'netCDF4._netCDF4.Variable'>\n float64 time_0(time_0)\n     axis: T\n     bounds: time_0_bnds\n     units: hours since 1970-01-01 00:00:00\n     standard_name: time\n     calendar: gregorian\n unlimited dimensions: \n current shape = (32,)\n filling on, default _FillValue of 9.969209968386869e+36 used,\n <class 'netCDF4._netCDF4.Variable'>\n float64 time_0_bnds(time_0, bnds)\n unlimited dimensions: \n current shape = (32, 2)\n filling on, default _FillValue of 9.969209968386869e+36 used,\n <class 'netCDF4._netCDF4.Variable'>\n int32 rotated_latitude_longitude()\n     grid_mapping_name: rotated_latitude_longitude\n     longitude_of_prime_meridian: 0.0\n     earth_radius: 6371229.0\n     grid_north_pole_latitude: 51.81999969482422\n     grid_north_pole_longitude: 289.8299865722656\n     north_pole_grid_longitude: 0.0\n unlimited dimensions: \n current shape = ()\n filling on, default _FillValue of -2147483647 used}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(ncds.variables.values()) - set(ncds.dimensions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<class 'netCDF4._netCDF4.Dimension'>: name = 'time_0', size = 32"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = list(ncds.dimensions.values())[-2]\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "masked_array(data=[3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n                   3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n                   3., 3., 3.],\n             mask=False,\n       fill_value=1e+20)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(ncds[dim.name][()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}